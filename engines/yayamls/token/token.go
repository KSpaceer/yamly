// Package token contains types and functions dedicated for lexical tokens
// generated by lexer.
package token

import (
	"strconv"

	"github.com/KSpaceer/yamly/engines/yayamls/yamlchar"
)

// Type defines token type.
type Type uint8

const (
	UnknownType Type = iota
	// SequenceEntryType represents a block style sequence entry indicator ("-")
	SequenceEntryType
	// MappingKeyType represents an explicit mapping key indicator ("?")
	MappingKeyType
	// MappingValueType represents a mapping value indicator (":")
	MappingValueType
	// CollectEntryType represents a flow style collect entry separator (",")
	CollectEntryType
	// SequenceStartType represents a flow style sequence start indicator ("[")
	SequenceStartType
	// SequenceEndType represents a flow style sequence end indicator ("]")
	SequenceEndType
	// MappingStartType represents a flow style mapping start indicator ("{")
	MappingStartType
	// MappingEndType represents a flow style mapping en indicator ("}")
	MappingEndType
	// CommentType represents a comment indicator ("#")
	CommentType
	// AnchorType represents an anchor indicator ("&")
	AnchorType
	// AliasType represents an alias indicator ("*")
	AliasType
	// TagType represents a tag indicator ("!")
	TagType
	// LiteralType represents a block style literal scalar start indicator ("|")
	LiteralType
	// FoldedType represents a block style folded scalar start indicator (">")
	FoldedType
	// SingleQuoteType represents a single quote ("'")
	SingleQuoteType
	// DoubleQuoteType represents a double quote ('"')
	DoubleQuoteType
	// DirectiveType represents a YAML directive indicator ("%")
	DirectiveType
	// LineBreakType represents a line break character sequence ("\n", "\r" or "\r\n")
	LineBreakType
	// SpaceType represents a single whitespace (" ")
	SpaceType
	// TabType represents a single tab ("\t")
	TabType
	// BOMType represents a byte-order mark
	BOMType
	// EOFType represents an end of file.
	EOFType
	// DocumentEndType represents a document end indicator ("...")
	DocumentEndType
	// DirectiveEndType represents a directive end indicator ("---")
	DirectiveEndType
	// StringType represents any string (like "key")
	StringType
	// StripChompingType represents a strip chomping indicator ("-")
	StripChompingType
	// KeepChompingType represents a keep chomping indicator ("+")
	KeepChompingType
)

func (t Type) String() string {
	switch t {
	case UnknownType:
		return "unknown"
	case SequenceEntryType:
		return "sequence-entry"
	case MappingKeyType:
		return "mapping-key"
	case MappingValueType:
		return "mapping-value"
	case CollectEntryType:
		return "collect-entry"
	case SequenceStartType:
		return "sequence-start"
	case SequenceEndType:
		return "sequence-end"
	case MappingStartType:
		return "mapping-start"
	case MappingEndType:
		return "mapping-end"
	case CommentType:
		return "comment"
	case AnchorType:
		return "anchor"
	case AliasType:
		return "alias"
	case TagType:
		return "tag"
	case LiteralType:
		return "literal"
	case FoldedType:
		return "folded"
	case SingleQuoteType:
		return "single-quote"
	case DoubleQuoteType:
		return "double-quote"
	case DirectiveType:
		return "directive"
	case LineBreakType:
		return "line-break"
	case SpaceType:
		return "space"
	case TabType:
		return "tab"
	case BOMType:
		return "byte-order-mark"
	case EOFType:
		return "end-of-file"
	case DocumentEndType:
		return "document-end"
	case DirectiveEndType:
		return "directive-end"
	case StringType:
		return "string"
	case KeepChompingType:
		return "keep-chomping"
	case StripChompingType:
		return "strip-chomping"
	default:
		return ""
	}
}

// IsWhiteSpace shows if provided token is whitespace (meaning space or tab)
func IsWhiteSpace(tok Token) bool {
	switch tok.Type {
	case SpaceType, TabType:
		return true
	default:
		return false
	}
}

// IsNonBreak shows if provided token is not a line-breaking token.
// EOF also considered line-breaking.
func IsNonBreak(tok Token) bool {
	switch tok.Type {
	case BOMType, LineBreakType, EOFType:
		return false
	default:
		return true
	}
}

// MayPrecedeWord shows if given token may precede word (or string).
func MayPrecedeWord(tok Token) bool {
	switch tok.Type {
	case SpaceType, TabType, LineBreakType, UnknownType:
		return true
	default:
		return false
	}
}

// IsOpeningFlowIndicator shows if provided token represents an opening flow object
// like mapping, sequence or their single element.
func IsOpeningFlowIndicator(tok Token) bool {
	switch tok.Type {
	case MappingStartType, SequenceStartType, CollectEntryType:
		return true
	default:
		return false
	}
}

// IsClosingFlowIndicator shows if provided token represents a closing flow object
// like mapping, sequence or their single element.
func IsClosingFlowIndicator(tok Token) bool {
	switch tok.Type {
	case MappingEndType, SequenceEndType, CollectEntryType:
		return true
	default:
		return false
	}
}

// Token represents a lexical unit produced by lexer.
type Token struct {
	Type            Type
	Start           Position
	End             Position
	Origin          string
	conformationMap conformationBitmap
}

func (t Token) String() string {
	return t.Type.String() + "[" + t.Origin + "]" + " Start:" +
		t.Start.String() + " End:" + t.End.String() + "\n"
}

func (t *Token) ConformsCharSet(cst yamlchar.CharSetType) bool {
	result, ok := t.conformationMap.Get(cst)
	if ok {
		return result
	}
	return t.slowConformation(cst)
}

func (t *Token) slowConformation(cst yamlchar.CharSetType) bool {
	result := yamlchar.ConformsCharSet(t.Origin, cst)
	t.conformationMap = t.conformationMap.Set(cst, result)
	return result
}

// Position represents token position in source text.
type Position struct {
	Row    int
	Column int
}

func (p Position) String() string {
	return "{{Row: " + strconv.Itoa(p.Row) + ", Column: " + strconv.Itoa(p.Column) + "}}"
}
